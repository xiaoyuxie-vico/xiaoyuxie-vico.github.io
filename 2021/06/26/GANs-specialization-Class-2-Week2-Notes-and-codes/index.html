<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    

    <title>GANs specialization Class 2 Week 2 Notes and codes | Machine Learning, Deep Learning, Computer Vision</title>
    <meta name="author" content="Xiaoyu Xie">
    
    <meta name="description" content="Track The past. Organize the present. Design the future.">
    
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta property="og:title" content="GANs specialization Class 2 Week 2 Notes and codes"/>
    <meta property="og:site_name" content="Xiaoyu Xie&#39;s Blog"/>

    
    <meta property="og:image" content=""/>
    

    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="alternate" href="/atom.xml" title="Xiaoyu Xie&#39;s Blog" type="application/atom+xml">
    <link rel="stylesheet" href="/css/lib/materialize.min.css">
    <link rel="stylesheet" href="/css/lib/font-awesome.min.css">
    <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">

    
        <link rel="stylesheet" href="/css/lib/prettify-tomorrow-night-eighties.css" type="text/css">
    
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
    <img src="/weixin_favicon.png" style="position: absolute; left: -9999px; opacity: 0; filter: alpha(opacity=0);">

    <nav class="indigo">
    <div class="nav-wrapper">
        <a href="#" data-activates="main-menu" class="button-collapse">
            <i class="fa fa-navicon"></i>
        </a>
        <div class="">
            <a href="/" class="brand-logo hide-on-med-and-down">Xiaoyu Xie&#39;s Blog</a>
            <ul class="right hide-on-med-and-down">
                
                    <li>
                        <a class="menu-home " href="/" >
                            <i class="fa fa-home "></i>
                            
                            Home
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-archive " href="/archives" >
                            <i class="fa fa-archive "></i>
                            
                            Archives
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                            <i class="fa fa-bookmark "></i>
                            
                            Categories
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-about " href="/about" >
                            <i class="fa fa-user "></i>
                            
                            About
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-search modal-trigger " href="#search" >
                            <i class="fa fa-search "></i>
                            
                            Search
                        </a>
                    </li>
                
            </ul>
            <div>
    <ul class="side-nav indigo darken-1" id="main-menu">
        
        <li class="side-user">
            <div class="row">
                <div class="col s4 no-padding">
                    <img class="avatar-image circle responsive-img" src="https://vico-image.oss-cn-hongkong.aliyuncs.com/avatar.jpg" alt="User Avatar">
                </div>
                <div class="info col s8 valign-wrapper no-padding">
                    <div class="valign">
                        <p class="name">Xiaoyu Xie</p>
                        <p class="desc">Deep Learning</p>
                    </div>
                </div>
            </div>
        </li>
        

        
            <li class="no-padding">
                <a class="waves-effect menu-home " href="/" >
                    <i class="fa fa-home "></i>
                    
                    Home
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-archive " href="/archives" >
                    <i class="fa fa-archive "></i>
                    
                    Archives
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                    <i class="fa fa-bookmark "></i>
                    
                    Categories
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-about " href="/about" >
                    <i class="fa fa-user "></i>
                    
                    About
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-search modal-trigger " href="#search" >
                    <i class="fa fa-search "></i>
                    
                    Search
                </a>
            </li>
        
    </ul>

    <ul class="side-nav indigo darken-1" id="category-menu">
    

            

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/Class-notes/">
                    Class-notes <span class="right">6</span></a>
                </a>
            </li>

        

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/Notes/">
                    Notes <span class="right">3</span></a>
                </a>
            </li>

        

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/Course-project/">
                    Course-project <span class="right">2</span></a>
                </a>
            </li>

        

    </ul>
</div>

        </div>
    </div>
</nav>

<div id="search" class="modal search-modal">
    <div class="row">
        <div class="input-field col s12">
              <input id="search-input" type="text">
              <label for="search-input">Search</label>
        </div>

    </div>
    <div id="search-result" class="search-result col s12">

    </div>
</div>


    <main>
        <div class="container main-container">
    <nav class="page-nav hide-on-small-only">
    <div class="nav-wrapper indigo">
        <span class="breadcrumb">Current page(Categories)</span>
        
            
    
    
    <a class="breadcrumb" href="/categories/Class-notes/">Class notes</a>


        

        
    </div>
</nav>

<article>
    <div class="card">
        <div class="card-content">
            

            <div class="article-title">
                
    
        <h1>GANs specialization Class 2 Week 2 Notes and codes</h1>
    


            </div>
            <time class="pink-link-context" datetime="2021-06-26T21:10:16.000Z"><a href="/2021/06/26/GANs-specialization-Class-2-Week2-Notes-and-codes/">2021-06-26</a></time>

            <span id="busuanzi_container_page_pv" class="read-times-container">
    <i class="fa fa-eye"></i>
    <span id="busuanzi_value_page_pv"></span>
</span>

            
    <div class="tags-row">
        
            <a href="/tags/Notes/" class="chip pink lighten-1">Notes</a>
        
            <a href="/tags/Online-course/" class="chip pink lighten-1">Online course</a>
        
            <a href="/tags/GANs/" class="chip pink lighten-1">GANs</a>
        
    </div>


            <div class="toc pink-link-context hide-on-med-and-down">
    <ol class="section table-of-contents"><li class="section table-of-contents-item section table-of-contents-level-1"><a class="section table-of-contents-link" href="#Class-2-week-2-assignment"><span class="section table-of-contents-text">Class 2 week 2 assignment</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Bias"><span class="section table-of-contents-text">Bias</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#Goals"><span class="section table-of-contents-text">Goals</span></a></li><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#Learning-Objectives"><span class="section table-of-contents-text">Learning Objectives</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Challenges"><span class="section table-of-contents-text">Challenges</span></a></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Getting-Started"><span class="section table-of-contents-text">Getting Started</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#Packages-and-Visualization"><span class="section table-of-contents-text">Packages and Visualization</span></a></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#Generator-and-Noise"><span class="section table-of-contents-text">Generator and Noise</span></a></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#Classifier"><span class="section table-of-contents-text">Classifier</span></a></li></ol></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Specifying-Parameters"><span class="section table-of-contents-text">Specifying Parameters</span></a></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Train-a-Classifier-Optional"><span class="section table-of-contents-text">Train a Classifier (Optional)</span></a></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Loading-the-Pre-trained-Models"><span class="section table-of-contents-text">Loading the Pre-trained Models</span></a></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Feature-Correlation"><span class="section table-of-contents-text">Feature Correlation</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#Note-on-CelebA"><span class="section table-of-contents-text">Note on CelebA</span></a></li></ol></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#Quantification"><span class="section table-of-contents-text">Quantification</span></a></li></ol></li></ol>
</div>


            <div class="entry pink-link-context">
                <h1 id="Class-2-week-2-assignment"><a href="#Class-2-week-2-assignment" class="headerlink" title="Class 2 week 2 assignment"></a>Class 2 week 2 assignment</h1><h2 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h2><h3 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h3><p>In this notebook, you’re going to explore a way to identify some biases of a GAN using a classifier, in a way that’s well-suited for attempting to make a model independent of an input. Note that not all biases are as obvious as the ones you will see here.</p>
<a id="more"></a>

<h3 id="Learning-Objectives"><a href="#Learning-Objectives" class="headerlink" title="Learning Objectives"></a>Learning Objectives</h3><ol>
<li> Be able to distinguish a few different kinds of bias in terms of demographic parity, equality of odds, and equality of opportunity (as proposed <a target="_blank" rel="noopener" href="http://m-mitchell.com/papers/Adversarial_Bias_Mitigation.pdf">here</a>).</li>
<li>Be able to use a classifier to try and detect biases in a GAN by analyzing the generator’s implicit associations.</li>
</ol>
<h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><p>One major challenge in assessing bias in GANs is that you still want your generator to be able to generate examples of different values of a protected class—the class you would like to mitigate bias against. While a classifier can be optimized to have its output be independent of a protected class, a generator which generates faces should be able to generate examples of various protected class values. </p>
<p>When you generate examples with various values of a protected class, you don’t want those examples to correspond to any properties that aren’t strictly a function of that protected class. This is made especially difficult since many protected classes (e.g. gender or ethnicity) are social constructs, and what properties count as “a function of that protected class” will vary depending on who you ask. It’s certainly a hard balance to strike.</p>
<p>Moreover, a protected class is rarely used to condition a GAN explicitly, so it is often necessary to resort to somewhat post-hoc methods (e.g. using a classifier trained on relevant features, which might be biased itself). </p>
<p>In this assignment, you will learn one approach to detect potential bias, by analyzing correlations in feature classifications on the generated images. </p>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p>As you have done previously, you will start by importing some useful libraries and defining a visualization function for your images. You will also use the same generator and basic classifier from previous weeks.</p>
<h4 id="Packages-and-Visualization"><a href="#Packages-and-Visualization" class="headerlink" title="Packages and Visualization"></a>Packages and Visualization</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> make_grid</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> CelebA</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">torch.manual_seed(<span class="number">0</span>) <span class="comment"># Set for our testing purposes, please do not change!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_tensor_images</span>(<span class="params">image_tensor, num_images=<span class="number">16</span>, size=(<span class="params"><span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span></span>), nrow=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Function for visualizing images: Given a tensor of images, number of images,</span></span><br><span class="line"><span class="string">    size per image, and images per row, plots and prints the images in an uniform grid.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    image_tensor = (image_tensor + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">    image_unflat = image_tensor.detach().cpu()</span><br><span class="line">    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)</span><br><span class="line">    plt.imshow(image_grid.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).squeeze())</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="Generator-and-Noise"><a href="#Generator-and-Noise" class="headerlink" title="Generator and Noise"></a>Generator and Noise</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Generator Class</span></span><br><span class="line"><span class="string">    Values:</span></span><br><span class="line"><span class="string">        z_dim: the dimension of the noise vector, a scalar</span></span><br><span class="line"><span class="string">        im_chan: the number of channels in the images, fitted for the dataset used, a scalar</span></span><br><span class="line"><span class="string">              (CelebA is rgb, so 3 is your default)</span></span><br><span class="line"><span class="string">        hidden_dim: the inner dimension, a scalar</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, z_dim=<span class="number">10</span>, im_chan=<span class="number">3</span>, hidden_dim=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.z_dim = z_dim</span><br><span class="line">        <span class="comment"># Build the neural network</span></span><br><span class="line">        self.gen = nn.Sequential(</span><br><span class="line">            self.make_gen_block(z_dim, hidden_dim * <span class="number">8</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim * <span class="number">8</span>, hidden_dim * <span class="number">4</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim * <span class="number">4</span>, hidden_dim * <span class="number">2</span>),</span><br><span class="line">            self.make_gen_block(hidden_dim * <span class="number">2</span>, hidden_dim),</span><br><span class="line">            self.make_gen_block(hidden_dim, im_chan, kernel_size=<span class="number">4</span>, final_layer=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_gen_block</span>(<span class="params">self, input_channels, output_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, final_layer=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Function to return a sequence of operations corresponding to a generator block of DCGAN;</span></span><br><span class="line"><span class="string">        a transposed convolution, a batchnorm (except in the final layer), and an activation.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            input_channels: how many channels the input feature representation has</span></span><br><span class="line"><span class="string">            output_channels: how many channels the output feature representation should have</span></span><br><span class="line"><span class="string">            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span></span><br><span class="line"><span class="string">            stride: the stride of the convolution</span></span><br><span class="line"><span class="string">            final_layer: a boolean, true if it is the final layer and false otherwise </span></span><br><span class="line"><span class="string">                      (affects activation and batchnorm)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> final_layer:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.BatchNorm2d(output_channels),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.Tanh(),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, noise</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Function for completing a forward pass of the generator: Given a noise tensor, </span></span><br><span class="line"><span class="string">        returns generated images.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            noise: a noise tensor with dimensions (n_samples, z_dim)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        x = noise.view(<span class="built_in">len</span>(noise), self.z_dim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.gen(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_noise</span>(<span class="params">n_samples, z_dim, device=<span class="string">&#x27;cpu&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)</span></span><br><span class="line"><span class="string">    creates a tensor of that shape filled with random numbers from the normal distribution.</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        n_samples: the number of samples to generate, a scalar</span></span><br><span class="line"><span class="string">        z_dim: the dimension of the noise vector, a scalar</span></span><br><span class="line"><span class="string">        device: the device type</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> torch.randn(n_samples, z_dim, device=device)</span><br></pre></td></tr></table></figure>
<h4 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Classifier Class</span></span><br><span class="line"><span class="string">    Values:</span></span><br><span class="line"><span class="string">        im_chan: the number of channels in the images, fitted for the dataset used, a scalar</span></span><br><span class="line"><span class="string">              (CelebA is rgb, so 3 is your default)</span></span><br><span class="line"><span class="string">        n_classes: the total number of classes in the dataset, an integer scalar</span></span><br><span class="line"><span class="string">        hidden_dim: the inner dimension, a scalar</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, im_chan=<span class="number">3</span>, n_classes=<span class="number">2</span>, hidden_dim=<span class="number">64</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            self.make_classifier_block(im_chan, hidden_dim),</span><br><span class="line">            self.make_classifier_block(hidden_dim, hidden_dim * <span class="number">2</span>),</span><br><span class="line">            self.make_classifier_block(hidden_dim * <span class="number">2</span>, hidden_dim * <span class="number">4</span>, stride=<span class="number">3</span>),</span><br><span class="line">            self.make_classifier_block(hidden_dim * <span class="number">4</span>, n_classes, final_layer=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_classifier_block</span>(<span class="params">self, input_channels, output_channels, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, final_layer=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Function to return a sequence of operations corresponding to a classifier block; </span></span><br><span class="line"><span class="string">        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            input_channels: how many channels the input feature representation has</span></span><br><span class="line"><span class="string">            output_channels: how many channels the output feature representation should have</span></span><br><span class="line"><span class="string">            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span></span><br><span class="line"><span class="string">            stride: the stride of the convolution</span></span><br><span class="line"><span class="string">            final_layer: a boolean, true if it is the final layer and false otherwise </span></span><br><span class="line"><span class="string">                      (affects activation and batchnorm)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> final_layer:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">                nn.BatchNorm2d(output_channels),</span><br><span class="line">                nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(input_channels, output_channels, kernel_size, stride),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, image</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Function for completing a forward pass of the classifier: Given an image tensor, </span></span><br><span class="line"><span class="string">        returns an n_classes-dimension tensor representing classes.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            image: a flattened image tensor with im_chan channels</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        class_pred = self.classifier(image)</span><br><span class="line">        <span class="keyword">return</span> class_pred.view(<span class="built_in">len</span>(class_pred), -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Specifying-Parameters"><a href="#Specifying-Parameters" class="headerlink" title="Specifying Parameters"></a>Specifying Parameters</h2><p>You will also need to specify a few parameters before you begin training:</p>
<ul>
<li>  z_dim: the dimension of the noise vector</li>
<li>  batch_size: the number of images per forward/backward pass</li>
<li>  device: the device type</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z_dim = <span class="number">64</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="Train-a-Classifier-Optional"><a href="#Train-a-Classifier-Optional" class="headerlink" title="Train a Classifier (Optional)"></a>Train a Classifier (Optional)</h2><p>You’re welcome to train your own classifier with this code, but you are provide a pre-trained one based on this architecture here which you can load and use in the next section. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># You can run this code to train your own classifier, but there is a provided pre-trained one </span></span><br><span class="line"><span class="comment"># If you&#x27;d like to use this, just run &quot;train_classifier(filename)&quot;</span></span><br><span class="line"><span class="comment"># To train and save a classifier on the label indices to that filename</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_classifier</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">    <span class="comment"># You&#x27;re going to target all the classes, so that&#x27;s how many the classifier will learn</span></span><br><span class="line">    label_indices = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">    n_epochs = <span class="number">3</span></span><br><span class="line">    display_step = <span class="number">500</span></span><br><span class="line">    lr = <span class="number">0.001</span></span><br><span class="line">    beta_1 = <span class="number">0.5</span></span><br><span class="line">    beta_2 = <span class="number">0.999</span></span><br><span class="line">    image_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize(image_size),</span><br><span class="line">        transforms.CenterCrop(image_size),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    dataloader = DataLoader(</span><br><span class="line">        CelebA(<span class="string">&quot;.&quot;</span>, split=<span class="string">&#x27;train&#x27;</span>, download=<span class="literal">True</span>, transform=transform),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    classifier = Classifier(n_classes=<span class="built_in">len</span>(label_indices)).to(device)</span><br><span class="line">    class_opt = torch.optim.Adam(classifier.parameters(), lr=lr, betas=(beta_1, beta_2))</span><br><span class="line">    criterion = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line">    cur_step = <span class="number">0</span></span><br><span class="line">    classifier_losses = []</span><br><span class="line">    <span class="comment"># classifier_val_losses = []</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">        <span class="comment"># Dataloader returns the batches</span></span><br><span class="line">        <span class="keyword">for</span> real, labels <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">            real = real.to(device)</span><br><span class="line">            labels = labels[:, label_indices].to(device).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">            class_opt.zero_grad()</span><br><span class="line">            class_pred = classifier(real)</span><br><span class="line">            class_loss = criterion(class_pred, labels)</span><br><span class="line">            class_loss.backward() <span class="comment"># Calculate the gradients</span></span><br><span class="line">            class_opt.step() <span class="comment"># Update the weights</span></span><br><span class="line">            classifier_losses += [class_loss.item()] <span class="comment"># Keep track of the average classifier loss</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">### Visualization code ###</span></span><br><span class="line">            <span class="keyword">if</span> cur_step % display_step == <span class="number">0</span> <span class="keyword">and</span> cur_step &gt; <span class="number">0</span>:</span><br><span class="line">                class_mean = <span class="built_in">sum</span>(classifier_losses[-display_step:]) / display_step</span><br><span class="line">                print(<span class="string">f&quot;Step <span class="subst">&#123;cur_step&#125;</span>: Classifier loss: <span class="subst">&#123;class_mean&#125;</span>&quot;</span>)</span><br><span class="line">                step_bins = <span class="number">20</span></span><br><span class="line">                x_axis = <span class="built_in">sorted</span>([i * step_bins <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classifier_losses) // step_bins)] * step_bins)</span><br><span class="line">                sns.lineplot(x_axis, classifier_losses[:<span class="built_in">len</span>(x_axis)], label=<span class="string">&quot;Classifier Loss&quot;</span>)</span><br><span class="line">                plt.legend()</span><br><span class="line">                plt.show()</span><br><span class="line">                torch.save(&#123;<span class="string">&quot;classifier&quot;</span>: classifier.state_dict()&#125;, filename)</span><br><span class="line">            cur_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the last line to train your own classfier - this line will not work in Coursera.</span></span><br><span class="line"><span class="comment"># If you&#x27;d like to do this, you&#x27;ll have to download it and run it, ideally using a GPU.</span></span><br><span class="line"><span class="comment"># train_classifier(&quot;filename&quot;)</span></span><br></pre></td></tr></table></figure>
<h2 id="Loading-the-Pre-trained-Models"><a href="#Loading-the-Pre-trained-Models" class="headerlink" title="Loading the Pre-trained Models"></a>Loading the Pre-trained Models</h2><p>You can now load the pre-trained generator (trained on CelebA) and classifier using the following code. If you trained your own classifier, you can load that one here instead. However, it is suggested that you first go through the assignment using the pre-trained one.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">gen = Generator(z_dim).to(device)</span><br><span class="line">gen_dict = torch.load(<span class="string">&quot;pretrained_celeba.pth&quot;</span>, map_location=torch.device(device))[<span class="string">&quot;gen&quot;</span>]</span><br><span class="line">gen.load_state_dict(gen_dict)</span><br><span class="line">gen.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">n_classes = <span class="number">40</span></span><br><span class="line">classifier = Classifier(n_classes=n_classes).to(device)</span><br><span class="line">class_dict = torch.load(<span class="string">&quot;pretrained_classifier.pth&quot;</span>, map_location=torch.device(device))[<span class="string">&quot;classifier&quot;</span>]</span><br><span class="line">classifier.load_state_dict(class_dict)</span><br><span class="line">classifier.<span class="built_in">eval</span>()</span><br><span class="line">print(<span class="string">&quot;Loaded the models!&quot;</span>)</span><br><span class="line"></span><br><span class="line">opt = torch.optim.Adam(classifier.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Loaded the models!</code></pre>
<h2 id="Feature-Correlation"><a href="#Feature-Correlation" class="headerlink" title="Feature Correlation"></a>Feature Correlation</h2><p>Now you can generate images using the generator. By also using the classifier, you will be generating images with different amounts of the “male” feature.</p>
<p>You are welcome to experiment with other features as the target feature, but it is encouraged that you initially go through the notebook as is before exploring.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First you generate a bunch of fake images with the generator</span></span><br><span class="line">n_images = <span class="number">256</span></span><br><span class="line">fake_image_history = []</span><br><span class="line">classification_history = []</span><br><span class="line">grad_steps = <span class="number">30</span> <span class="comment"># How many gradient steps to take</span></span><br><span class="line">skip = <span class="number">2</span> <span class="comment"># How many gradient steps to skip in the visualization</span></span><br><span class="line"></span><br><span class="line">feature_names = [<span class="string">&quot;5oClockShadow&quot;</span>, <span class="string">&quot;ArchedEyebrows&quot;</span>, <span class="string">&quot;Attractive&quot;</span>, <span class="string">&quot;BagsUnderEyes&quot;</span>, <span class="string">&quot;Bald&quot;</span>, <span class="string">&quot;Bangs&quot;</span>,</span><br><span class="line"><span class="string">&quot;BigLips&quot;</span>, <span class="string">&quot;BigNose&quot;</span>, <span class="string">&quot;BlackHair&quot;</span>, <span class="string">&quot;BlondHair&quot;</span>, <span class="string">&quot;Blurry&quot;</span>, <span class="string">&quot;BrownHair&quot;</span>, <span class="string">&quot;BushyEyebrows&quot;</span>, <span class="string">&quot;Chubby&quot;</span>,</span><br><span class="line"><span class="string">&quot;DoubleChin&quot;</span>, <span class="string">&quot;Eyeglasses&quot;</span>, <span class="string">&quot;Goatee&quot;</span>, <span class="string">&quot;GrayHair&quot;</span>, <span class="string">&quot;HeavyMakeup&quot;</span>, <span class="string">&quot;HighCheekbones&quot;</span>, <span class="string">&quot;Male&quot;</span>, </span><br><span class="line"><span class="string">&quot;MouthSlightlyOpen&quot;</span>, <span class="string">&quot;Mustache&quot;</span>, <span class="string">&quot;NarrowEyes&quot;</span>, <span class="string">&quot;NoBeard&quot;</span>, <span class="string">&quot;OvalFace&quot;</span>, <span class="string">&quot;PaleSkin&quot;</span>, <span class="string">&quot;PointyNose&quot;</span>, </span><br><span class="line"><span class="string">&quot;RecedingHairline&quot;</span>, <span class="string">&quot;RosyCheeks&quot;</span>, <span class="string">&quot;Sideburn&quot;</span>, <span class="string">&quot;Smiling&quot;</span>, <span class="string">&quot;StraightHair&quot;</span>, <span class="string">&quot;WavyHair&quot;</span>, <span class="string">&quot;WearingEarrings&quot;</span>, </span><br><span class="line"><span class="string">&quot;WearingHat&quot;</span>, <span class="string">&quot;WearingLipstick&quot;</span>, <span class="string">&quot;WearingNecklace&quot;</span>, <span class="string">&quot;WearingNecktie&quot;</span>, <span class="string">&quot;Young&quot;</span>]</span><br><span class="line"></span><br><span class="line">n_features = <span class="built_in">len</span>(feature_names)</span><br><span class="line"><span class="comment"># Set the target feature</span></span><br><span class="line">target_feature = <span class="string">&quot;Male&quot;</span></span><br><span class="line">target_indices = feature_names.index(target_feature)</span><br><span class="line">noise = get_noise(n_images, z_dim).to(device)</span><br><span class="line">new_noise = noise.clone().requires_grad_()</span><br><span class="line">starting_classifications = classifier(gen(new_noise)).cpu().detach()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Additive direction (more of a feature)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(grad_steps):</span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    fake = gen(new_noise)</span><br><span class="line">    fake_image_history += [fake]</span><br><span class="line">    classifications = classifier(fake)</span><br><span class="line">    classification_history += [classifications.cpu().detach()]</span><br><span class="line">    fake_classes = classifications[:, target_indices].mean()</span><br><span class="line">    fake_classes.backward()</span><br><span class="line">    new_noise.data += new_noise.grad / grad_steps</span><br><span class="line"></span><br><span class="line"><span class="comment"># Subtractive direction (less of a feature)</span></span><br><span class="line">new_noise = noise.clone().requires_grad_()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(grad_steps):</span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    fake = gen(new_noise)</span><br><span class="line">    fake_image_history += [fake]</span><br><span class="line">    classifications = classifier(fake)</span><br><span class="line">    classification_history += [classifications.cpu().detach()]</span><br><span class="line">    fake_classes = classifications[:, target_indices].mean()</span><br><span class="line">    fake_classes.backward()</span><br><span class="line">    new_noise.data -= new_noise.grad / grad_steps</span><br><span class="line"></span><br><span class="line">classification_history = torch.stack(classification_history)</span><br></pre></td></tr></table></figure>
<p>You’ve now generated image samples, which have increasing or decreasing amounts of the target feature. You can visualize the way in which that affects other classified features. The x-axis will show you the amount of change in your target feature and the y-axis shows how much the other features change, as detected in those images by the classifier. Together, you will be able to see the covariance of “male-ness” and other features.</p>
<p>You are started off with a set of features that have interesting associations with “male-ness”, but you are welcome to change the features in <code>other_features</code> with others from <code>feature_names</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment"># Set the other features</span></span><br><span class="line">other_features = [<span class="string">&quot;Smiling&quot;</span>, <span class="string">&quot;Bald&quot;</span>, <span class="string">&quot;Young&quot;</span>, <span class="string">&quot;HeavyMakeup&quot;</span>, <span class="string">&quot;Attractive&quot;</span>]</span><br><span class="line">classification_changes = (classification_history - starting_classifications[<span class="literal">None</span>, :, :]).numpy()</span><br><span class="line"><span class="keyword">for</span> other_feature <span class="keyword">in</span> other_features:</span><br><span class="line">    other_indices = feature_names.index(other_feature)</span><br><span class="line">    <span class="keyword">with</span> sns.axes_style(<span class="string">&quot;darkgrid&quot;</span>):</span><br><span class="line">        sns.regplot(</span><br><span class="line">            classification_changes[:, :, target_indices].reshape(-<span class="number">1</span>), </span><br><span class="line">            classification_changes[:, :, other_indices].reshape(-<span class="number">1</span>), </span><br><span class="line">            fit_reg=<span class="literal">True</span>,</span><br><span class="line">            truncate=<span class="literal">True</span>,</span><br><span class="line">            ci=<span class="number">99</span>,</span><br><span class="line">            x_ci=<span class="number">99</span>,</span><br><span class="line">            x_bins=<span class="built_in">len</span>(classification_history),</span><br><span class="line">            label=other_feature</span><br><span class="line">        )</span><br><span class="line">plt.xlabel(target_feature)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Other Feature&quot;</span>)</span><br><span class="line">plt.title(<span class="string">f&quot;Generator Biases: Features vs <span class="subst">&#123;target_feature&#125;</span>-ness&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="output_19_0.png" alt="png"></p>
<p>This correlation detection can be used to reduce bias by penalizing this type of correlation in the loss during the training of the generator. However, currently there is no rigorous and accepted solution for debiasing GANs. A first step that you can take in the right direction comes before training the model: make sure that your dataset is inclusive and representative, and consider how you can mitigate the biases resulting from whatever data collection method you used—for example, getting a representative labelers for your task. </p>
<p>It is important to note that, as highlighted in the lecture and by many researchers including <a target="_blank" rel="noopener" href="https://sites.google.com/view/fatecv-tutorial/schedule">Timnit Gebru and Emily Denton</a>, a diverse dataset alone is not enough to eliminate bias. Even diverse datasets can reinforce existing structural biases by simply capturing common social biases. Mitigating these biases is an important and active area of research.</p>
<h4 id="Note-on-CelebA"><a href="#Note-on-CelebA" class="headerlink" title="Note on CelebA"></a>Note on CelebA</h4><p>You may have noticed that there are obvious correlations between the feature you are using, “male”, and other seemingly unrelates features, “smiling” and “young” for example. This is because the CelebA dataset labels had no serious consideration for diversity. The data represents the biases their labelers, the dataset creators, the social biases as a result of using a dataset based on American celebrities, and many others. Equipped with knowledge about bias, we trust that you will do better in the future datasets you create.</p>
<h2 id="Quantification"><a href="#Quantification" class="headerlink" title="Quantification"></a>Quantification</h2><p>Finally, you can also quantitatively evaluate the degree to which these factors covary. Given a target index, for example corresponding to “male,” you’ll want to return the other features that covary with that target feature the most. You’ll want to account for both large negative and positive covariances, and you’ll want to avoid returning the target feature in your list of covarying features (since a feature will often have a high covariance with itself). You’ll complete some helper functions first, each of which should be one or two lines long.</p>
<details>

<summary>
<font size="3" color="green">
<b>Optional hints for <code><font size="4">covariance_matrix_from_examples</font></code></b>
</font>
</summary>

<ol>
<li>  You will likely find the following function useful: <a target="_blank" rel="noopener" href="https://numpy.org/doc/stable/reference/generated/numpy.cov.html">np.cov</a>. Note the <code>rowvar</code> parameter.</li>
<li>  You will probably find it useful to <a target="_blank" rel="noopener" href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html">reshape</a> the input.</details>


</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.distributions <span class="keyword">import</span> MultivariateNormal</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">covariance_matrix_from_examples</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Helper function for get_top_covariances to calculate a covariance matrix. </span></span><br><span class="line"><span class="string">    Parameter: examples: a list of steps corresponding to samples of shape (2 * grad_steps, n_images, n_features)</span></span><br><span class="line"><span class="string">    Returns: the (n_features, n_features) covariance matrix from the examples</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Hint: np.cov will be useful here - note the rowvar argument!</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    flattened_changes = examples.reshape(-<span class="number">1</span>, examples.shape[-<span class="number">1</span>]).T</span><br><span class="line">    covariances = np.cov(flattened_changes)</span><br><span class="line">    <span class="keyword">return</span> covariances</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">mean = torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]) </span><br><span class="line">covariance = torch.Tensor( </span><br><span class="line">    [[<span class="number">10</span>, <span class="number">2</span>, -<span class="number">0.5</span>, -<span class="number">5</span>],</span><br><span class="line">     [<span class="number">2</span>, <span class="number">11</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">     [-<span class="number">0.5</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">2</span>],</span><br><span class="line">     [-<span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">11</span>]]</span><br><span class="line">)</span><br><span class="line">samples = MultivariateNormal(mean, covariance).sample((<span class="number">60</span> * <span class="number">128</span>,))</span><br><span class="line">foo = samples.reshape(<span class="number">60</span>, <span class="number">128</span>, samples.shape[-<span class="number">1</span>]).numpy()</span><br><span class="line"><span class="keyword">assert</span> np.<span class="built_in">all</span>(np.<span class="built_in">abs</span>(covariance_matrix_from_examples(foo) - covariance.numpy()) &lt; <span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">&quot;covariance_matrix_from_examples works!&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>covariance_matrix_from_examples works!</code></pre>
<p>Now you’ll write a helper function to return the indices of a numpy array in order of magnitude.</p>
<details>
<summary>
<font size="3" color="green">
<b>Optional hints for <code><font size="4">get_top_magnitude_indices</font></code></b>
</font>
</summary>

<ol start="4">
<li>  Feel free to use any reasonable method to get the largest elements - you may find <a target="_blank" rel="noopener" href="https://numpy.org/doc/stable/reference/generated/numpy.argsort.html">np.argsort</a> useful here.</details>


</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top_magnitude_indices</span>(<span class="params">values</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Helper function for get_top_covariances to get indices by magnitude. </span></span><br><span class="line"><span class="string">    Parameter: values, a list of values as a numpy array of shape (n_values)</span></span><br><span class="line"><span class="string">    Returns: numpy array of indices sorted from greatest to least by the magnitudes of their corresponding values</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Hint: This can be done in one or two lines using np.argsort and np.abs!</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    top_indices = np.argsort(np.<span class="built_in">abs</span>(values))[::-<span class="number">1</span>]</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> top_indices</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> get_top_magnitude_indices([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]).tolist() == [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">assert</span> get_top_magnitude_indices([-<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]).tolist() == [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">print(<span class="string">&quot;get_top_magnitude_indices works!&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>get_top_magnitude_indices works!</code></pre>
<p>Now you’ll write a helper function to return a list with an element removed by the value, in an unchanged order. In this case, you won’t have to remove any values multiple times, so don’t worry about how you handle multiple examples.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_from_list</span>(<span class="params">indices, index_to_remove</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Helper function for get_top_covariances to remove an index from an array. </span></span><br><span class="line"><span class="string">    Parameter: indices, a list of indices as a numpy array of shape (n_indices)</span></span><br><span class="line"><span class="string">    Returns: the numpy array of indices in the same order without index_to_remove</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Hint: There are many ways to do this, but please don&#x27;t edit the list in-place.</span></span><br><span class="line">    <span class="comment"># If you&#x27;re not very familiar with array indexing, you may find this page helpful:</span></span><br><span class="line">    <span class="comment"># https://numpy.org/devdocs/reference/arrays.indexing.html (especially boolean indexing)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    new_indices = np.delete(indices, np.where(indices==index_to_remove))</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> new_indices</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> remove_from_list(np.array([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]), <span class="number">1</span>).tolist() == [<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>]</span><br><span class="line">print(<span class="string">&quot;remove_from_list works!&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>remove_from_list works!</code></pre>
<p>Now, you can put the above helper functions together.</p>
<details>
<summary>
<font size="3" color="green">
<b>Optional hints for <code><font size="4">get_top_covariances</font></code></b>
</font>
</summary>

<ol>
<li>  Start by finding the covariance matrix</li>
<li>  The target feature should not be included in the outputs.</li>
<li>  It may be easiest to solve this if you find the <code>relevant_indices</code> first, and then use <code>relevant_indices</code> to calculate <code>highest_covariances</code>.</li>
<li>  You want to sort by absolute value but return the actual values.</details>


</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="comment"># GRADED CELL: get_top_covariances</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top_covariances</span>(<span class="params">classification_changes, target_index, top_n=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Function for getting the top n covariances: Given a list of classification changes</span></span><br><span class="line"><span class="string">    and the index of the target feature, returns </span></span><br><span class="line"><span class="string">    (1) relevant_indices: a list or tensor (numpy or torch) of the indices corresponding </span></span><br><span class="line"><span class="string">        to the n features that covary most with the target in terms of absolute covariance</span></span><br><span class="line"><span class="string">    (2) highest_covariances: a list or tensor of the degrees to which they covary.</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        classification_changes: relative changes in classifications of each generated image </span></span><br><span class="line"><span class="string">          resulting from optimizing the target feature (see above for a visualization)</span></span><br><span class="line"><span class="string">        target_index: the index of the target feature, a scalar</span></span><br><span class="line"><span class="string">        top_n: the top most number of elements to return, default is 10</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Hint: Don&#x27;t forget you also care about negative covariances!</span></span><br><span class="line">    <span class="comment"># Note that classification_changes has a shape of (2 * grad_steps, n_images, n_features) </span></span><br><span class="line">    <span class="comment"># where n_features is the number of features measured by the classifier, and you are looking</span></span><br><span class="line">    <span class="comment"># for the covariance of the features based on the (2 * grad_steps * n_images) samples.</span></span><br><span class="line">    <span class="comment">#### START CODE HERE ####</span></span><br><span class="line"><span class="comment">#     cov_matrix = get_top_magnitude_indices(classification_changes.reshape(-1, classification_changes.shape[2]))</span></span><br><span class="line">    cov_matrix = np.cov(classification_changes.reshape(-<span class="number">1</span>, classification_changes.shape[<span class="number">2</span>]), rowvar=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    relevant_indices = get_top_magnitude_indices(cov_matrix[target_index,:])</span><br><span class="line">    relevant_indices = remove_from_list(relevant_indices, target_index)</span><br><span class="line">    relevant_indices = relevant_indices[:top_n]</span><br><span class="line">    highest_covariances = cov_matrix[:, relevant_indices][target_index]</span><br><span class="line">    </span><br><span class="line"><span class="comment">#     cov_matrix = np.cov(classification_changes.reshape(-1, classification_changes.shape[2]), rowvar=False)</span></span><br><span class="line"><span class="comment">#     relevant_indices = np.abs(cov_matrix[target_index, :]).argsort()[:top_n+1][::-1]</span></span><br><span class="line"><span class="comment">#     relevant_indices = np.delete(relevant_indices, np.where(relevant_indices == target_index))</span></span><br><span class="line"><span class="comment">#     relevant_indices = relevant_indices[:top_n]</span></span><br><span class="line"><span class="comment">#     highest_covariances = cov_matrix[:, relevant_indices][target_index]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#### END CODE HERE ####</span></span><br><span class="line">    <span class="keyword">return</span> relevant_indices, highest_covariances</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNIT TEST</span></span><br><span class="line"><span class="keyword">from</span> torch.distributions <span class="keyword">import</span> MultivariateNormal</span><br><span class="line">mean = torch.Tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]) </span><br><span class="line">covariance = torch.Tensor( </span><br><span class="line">    [[<span class="number">10</span>, <span class="number">2</span>, -<span class="number">0.5</span>, -<span class="number">5</span>],</span><br><span class="line">     [<span class="number">2</span>, <span class="number">11</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">     [-<span class="number">0.5</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">2</span>],</span><br><span class="line">     [-<span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">11</span>]]</span><br><span class="line">)</span><br><span class="line">independent_dist = MultivariateNormal(mean, covariance)</span><br><span class="line">samples = independent_dist.sample((<span class="number">60</span> * <span class="number">128</span>,))</span><br><span class="line">foo = samples.reshape(<span class="number">60</span>, <span class="number">128</span>, samples.shape[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">relevant_indices, highest_covariances = get_top_covariances(foo, <span class="number">1</span>, top_n=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">assert</span> (<span class="built_in">tuple</span>(relevant_indices) == (<span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>)), <span class="string">&quot;Make sure you&#x27;re getting the greatest, not the least covariances&quot;</span></span><br><span class="line"><span class="keyword">assert</span> np.<span class="built_in">all</span>(np.<span class="built_in">abs</span>(highest_covariances - [<span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>]) &lt; <span class="number">0.5</span> )</span><br><span class="line"></span><br><span class="line">relevant_indices, highest_covariances = get_top_covariances(foo, <span class="number">0</span>, top_n=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">assert</span> (<span class="built_in">tuple</span>(relevant_indices) == (<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)), <span class="string">&quot;Make sure to consider the magnitude of negative covariances&quot;</span></span><br><span class="line"><span class="keyword">assert</span> np.<span class="built_in">all</span>(np.<span class="built_in">abs</span>(highest_covariances - [-<span class="number">5</span>, <span class="number">2</span>, -<span class="number">0.5</span>]) &lt; <span class="number">0.5</span> )</span><br><span class="line"></span><br><span class="line">relevant_indices, highest_covariances = get_top_covariances(foo, <span class="number">2</span>, top_n=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">assert</span> (<span class="built_in">tuple</span>(relevant_indices) == (<span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">assert</span> np.<span class="built_in">all</span>(np.<span class="built_in">abs</span>(highest_covariances - [<span class="number">5</span>, <span class="number">2</span>]) &lt; <span class="number">0.5</span> )</span><br><span class="line"></span><br><span class="line">relevant_indices, highest_covariances = get_top_covariances(foo, <span class="number">3</span>, top_n=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">assert</span> (<span class="built_in">tuple</span>(relevant_indices) == (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">assert</span> np.<span class="built_in">all</span>(np.<span class="built_in">abs</span>(highest_covariances - [-<span class="number">5</span>, <span class="number">4</span>]) &lt; <span class="number">0.5</span> )</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;All tests passed&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>All tests passed</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">relevant_indices, highest_covariances = get_top_covariances(classification_changes, target_indices, top_n=<span class="number">10</span>)</span><br><span class="line">print(relevant_indices)</span><br><span class="line"><span class="keyword">assert</span> relevant_indices[<span class="number">9</span>] == <span class="number">34</span></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(relevant_indices) == <span class="number">10</span></span><br><span class="line"><span class="keyword">assert</span> highest_covariances[<span class="number">8</span>] - (-<span class="number">1.2418</span>) &lt; <span class="number">1e-3</span></span><br><span class="line"><span class="keyword">for</span> index, covariance <span class="keyword">in</span> <span class="built_in">zip</span>(relevant_indices, highest_covariances):</span><br><span class="line">    print(<span class="string">f&quot;<span class="subst">&#123;feature_names[index]&#125;</span>  <span class="subst">&#123;covariance:f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[36 18 24 30  0 22 16 38  9 34]
WearingLipstick  -2.952777
HeavyMakeup  -2.705970
NoBeard  -2.559992
Sideburn  2.049631
5oClockShadow  2.006905
Mustache  1.998550
Goatee  1.859620
WearingNecktie  1.583763
BlondHair  -1.241823
WearingEarrings  -1.207922</code></pre>
<p>One of the major sources of difficulty with identifying bias and fairness, as discussed in the lectures, is that there are many ways you might reasonably define these terms. Here are three ways that are computationally useful and <a target="_blank" rel="noopener" href="http://m-mitchell.com/papers/Adversarial_Bias_Mitigation.pdf">widely referenced</a>. They are, by no means, the only definitions of fairness (see more details <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary/fairness">here</a>):</p>
<ol>
<li>  Demographic parity: the overall distribution of the predictions made by a predictor is the same for different values of a protected class. </li>
<li>  Equality of odds: all else being equal, the probability that you predict correctly or incorrectly is the same for different values of a protected class. </li>
<li>  Equality of opportunity: all else being equal, the probability that you predict correctly is the same for different valus of a protected class (weaker than equality of odds).</li>
</ol>
<p>With GANs also being used to help downstream classifiers (you will see this firsthand in future assignments), these definitions of fairness will impact, as well as depend on, your downstream task. It is important to work towards creating a fair GAN according to the definition you choose. Pursuing any of them is virtually always better than blindly labelling data, creating a GAN, and sampling its generations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
                
<p class="pink-link-context">
    <a href="/2022/01/29/What-is-Scientific-Machine-Learning-and-Physics-informed-Machine-Learning/" rel="next" title="What is Scientific Machine Learning and Physics-informed Machine Learning?">
    Prev: What is Scientific Machine Learning and Physics-informed Machine Learning?
  </a>
</p>



<p class="pink-link-context">
    <a href="/2021/06/26/GANs-specialization-Class-2-Week3-Notes-and-codes/" rel="next" title="GANs specialization Class 2 Week 3 Notes and codes">
    Next: GANs specialization Class 2 Week 3 Notes and codes
  </a>
</p>


            </div>
			
        </div>
    </div>
</article>






</div>

        <div class="fixed-action-btn float-sitemap">
    <a class="btn-floating btn-large pink">
      <i class="fa fa-caret-square-o-up"></i>
    </a>
    <ul>
      <li><a class="btn-return-top btn-floating waves-effect green" title="Return to top"><i class="fa fa-arrow-circle-o-up"></i></a></li>
      <li><a class="btn-floating waves-effect button-collapse yellow darken-1"  data-activates="main-menu" title="Menu"><i class="fa fa-navicon"></i></a></li>
    </ul>
  </div>

    </main>
    <footer class="page-footer indigo darken-1">
    
    <div class="footer-container container">
        <div class="row">
            
            <div class="social-group col m4 s12">
                <h5 class="white-text">Social</h5>
                
                    <a class="social-link" href="https://github.com/xiaoyuxie-vico" target="_blank">
                        <i class="fa fa-2x fa-github"></i>
                    </a>
                
                
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
    <div class="site-visitors-container white-text">
        <span>
            <i class="fa fa-user"></i>
            <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
        </span>
        <span>&nbsp;|&nbsp;</span>
        <span>
            <i class="fa fa-eye"></i>
            <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
        </span>
    </div>


            </div>
            

            
            <div class="col m8 s12">
                <h5 class="white-text">Links</h5>
                
                    <a class="social-link" href="xiaoyuxie.vico@gmail.com" target="_blank">Email</a>
                
                    <a class="social-link" href="https://www.linkedin.com/in/xyxie/" target="_blank">Linkedin</a>
                
            </div>
            
        </div>
    </div>
    

    <div class="footer-copyright pink-link-context">
        <div class="container">
            © 2016 example.com, All rights reserved.
            <p class="right" style="margin-top: 0;">Blog powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> | Theme <a target="_blank" rel="noopener" href="https://github.com/raytaylorlin/hexo-theme-raytaylorism">raytaylorism</a></p>
        </div>
    </div>
</footer>


    <noscript>
    <div class="noscript">
        <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
    </div>
</noscript>
<div class="noscript">
    <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
</div>


<script src="/js/jquery.min.js"></script>
<script src="/js/materialize.min.js"></script>

<script>
    (function($) {
        $(document).ready(function() {
            // 隐藏禁用javascript（针对微信内置浏览器）的提示
            $('.noscript').hide();

            // 图片缩放效果
            var $imgs = $('img').not('.slider-image').not('.avatar-image').not('.carousel-image').not('.card-cover-image').not('.qrcode');

            // 给图片加上点击放大效果（materialbox插件）
            $imgs.addClass('materialboxed').each(function(i, el) {
                $(this).attr('data-caption', $(this).attr('alt') || ' ');
            }).materialbox();

            // 优化表格的显示
            $('table').each(function() {
                var $table = $(this);
                // 除去多行代码的情况
                if ($table.find('pre').length == 0) {
                    $table.addClass('responsive-table striped bordered');
                }
            });

            // 首页幻灯片
            $('.slider').slider({indicators: true, full_width: true, interval: 8000});

            $(".button-collapse").sideNav();
            $(".category-menu").sideNav();

            // 针对gallery post
            $('.carousel').carousel({full_width: true});
            $('.carousel-control.prev').click(function() {
                $('.carousel').carousel('prev');
            });
            $('.carousel-control.next').click(function() {
                $('.carousel').carousel('next');
            });

            // 文章目录
            $('article').not('.simple-article').find('h1').add('h2').add('h3').add('h4').add('h5').add('h6').scrollSpy();

            // 目录随屏幕滚动（防止目录过长越过footer）
            var $toc = $('.toc');
            var scrollTargetTop = 0;
            $(window).scroll(function() {
                var $activeLink = $toc.find('a.active.section');
                if ($(window).scrollTop() < 100) {
                    scrollTargetTop = 0;
                } else {
                    if ($activeLink[0]) {
                        scrollTargetTop = $activeLink.offset().top - $toc.offset().top;
                    }
                }
                $toc.css('top', '-' + scrollTargetTop + 'px');
            });

            // 修正文章目录的left-border颜色
            var color = $('.table-of-contents-text').css('color');
            $('.table-of-contents-link').css('border-left-color', color);

            // 针对移动端做的优化：FAB按钮点击一下收回
            if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
                $('.fixed-action-btn').addClass('click-to-toggle');
            }
            // 回到顶部
            $('.btn-return-top').click(function() {
                $('body, html').animate({
                    scrollTop: 0
                }, 500);
            });

            // 重置读书页面的Tab标签页的颜色
            $('li.tab a').hover(function() {
                $(this).toggleClass('text-lighten-4');
            });
            $('.indicator').addClass('pink lighten-2');

            
            // 添加new标签
            $('.menu-about').append('<span class="new badge pink"></span>');
            

            // 搜索功能
            $('.modal-trigger').leanModal({
                // 打开搜索框时自动聚焦
                ready: function() {
                    if ($('#search').is(":visible")) {
                        $('#search-input').focus();
                    }
                }
            });
            var searchXml = "search.xml";
            if (searchXml.length == 0) {
             	searchXml = "search.xml";
            }
            var searchPath = "/" + searchXml;
            initSearch(searchPath, 'search-input', 'search-result');
        });

        // 初始化搜索与匹配函数
        var initSearch = function(path, search_id, content_id) {
            'use strict';
            $.ajax({
                url: path,
                dataType: "xml",
                success: function(xmlResponse) {
                    // get the contents from search data
                    var datas = $("entry", xmlResponse).map(function() {
                        return {
                            title: $("title", this).text(),
                            content: $("content", this).text(),
                            url: $("url", this).text()
                        };
                    }).get();
                    var $input = document.getElementById(search_id);
                    var $resultContent = document.getElementById(content_id);
                    $input.addEventListener('input', function() {
                        var str = '<ul class=\"search-result-list\">';
                        var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                        $resultContent.innerHTML = "";
                        if (this.value.trim().length <= 0) {
                            return;
                        }
                        // perform local searching
                        datas.forEach(function(data) {
                            var isMatch = true;
                            var content_index = [];
                            var data_title = data.title.trim().toLowerCase();
                            var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                            var data_url = data.url;
                            var index_title = -1;
                            var index_content = -1;
                            var first_occur = -1;
                            // only match artiles with not empty titles and contents
                            if (data_title != '' && data_content != '') {
                                keywords.forEach(function(keyword, i) {
                                    index_title = data_title.indexOf(keyword);
                                    index_content = data_content.indexOf(keyword);
                                    if (index_title < 0 && index_content < 0) {
                                        isMatch = false;
                                    } else {
                                        if (index_content < 0) {
                                            index_content = 0;
                                        }
                                        if (i == 0) {
                                            first_occur = index_content;
                                        }
                                    }
                                });
                            }
                            // show search results
                            if (isMatch) {
                                keywords.forEach(function(keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    data_title = data_title.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                });

                                str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                                var content = data.content.trim().replace(/<[^>]+>/g, "");
                                if (first_occur >= 0) {
                                    // cut out 100 characters
                                    var start = first_occur - 20;
                                    var end = first_occur + 80;
                                    if (start < 0) {
                                        start = 0;
                                    }
                                    if (start == 0) {
                                        end = 100;
                                    }
                                    if (end > content.length) {
                                        end = content.length;
                                    }
                                    var match_content = content.substring(start, end);
                                    // highlight all keywords
                                    keywords.forEach(function(keyword) {
                                        var regS = new RegExp(keyword, "gi");
                                        match_content = match_content.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                    });

                                    str += "<p class=\"search-result\">..." + match_content + "...</p>"
                                }
                                str += "</li>";
                            }
                        });
                        str += "</ul>";
                        $resultContent.innerHTML = str;
                    });
                }
            });
        }
    })(jQuery);
</script>


<script src="/js/prettify.js"></script>
<script type="text/javascript">
    $(document).ready(function() {
        $("pre").addClass("prettyprint");
        prettyPrint();
    });
</script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



</body>
</html>
