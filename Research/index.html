<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Xiaoyu Xie's Blog</title><meta name="author" content="Xiaoyu Xie"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Xiaoyu Xie's Blog" type="application/atom+xml">
</head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Xiaoyu Xie's Blog</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/#Home"> Home</a></li><li class="menus_item"><a class="site-page" href="/Research"> Research</a></li><li class="menus_item"><a class="site-page" href="/Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/Awards"> Awards</a></li><li class="menus_item"><a class="site-page" href="/Teaching"> Teaching</a></li><li class="menus_item"><a class="site-page" href="/Media"> Media</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Xiaoyu Xie</h3><p class="author-bio">PhD candidate at Northwestern University</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://github.com/xiaoyuxie-vico" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/xyxie" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="xiaoyuxie2020@u.northwestern.edu" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.com/citations?user=A5idlREAAAAJ&amp;hl=en&amp;oi=ao" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li></ul></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Research</h2><article><p>There’s a memorable quote from the TV show <em>Westworld</em> that resonates deeply with my research motivation and direction:</p>
<blockquote>
<p> Some people choose to see the ugliness in this world. I choose to see the beauty. To believe there is an order to our days, a purpose.</p>
</blockquote>
<p>To me, this order and beauty take shape in the form of equations—like Newton’s laws of motion (F=ma) or Einstein’s mass-energy equivalence (e=mc^2). Mathematical equations and principles underlie the world as we know it, elucidating natural phenomena, accelerating technological advancements, and refining our understanding of life.</p>
<p>Traditionally, scientists have devoted centuries to foundational work based on assumptions, hypotheses, and principles to derive transformative equations. But the arrival of artificial intelligence (AI) promises to expedite this discovery process, unearthing the hidden patterns and knowledge in intricate systems and phenomena.</p>
<p>However, most AI research today focuses solely on data-driven approaches, often leading to “black box” models. These models tend to possess low interpretability, limited generalization, and a heavy dependence on vast datasets, presenting challenges to their accuracy and elucidation.</p>
<p>In order to mitigate these issues, there is a pressing need to interweave AI with our existing body of knowledge. In other words, AI must embrace mathematical and natural principles, such as partial differential equations and physical invariance. There’s an urgent need for innovative strategies and frameworks that incorporate our existing knowledge into machine learning and deep learning, rather than merely leaning on data. This kind of integration paves the way for <em>Scientific or Mechanistic Machine Learning</em>, also referred to as <em>AI4Science</em>.</p>
<p>My research on Dimensionless Learning stands as an embodiment of this progressive paradigm. We embed fundamental physical invariances, such as dimensional invariance, into machine learning algorithms. This innovative approach allows us to discover three levels of knowledge: dimensionless numbers at the feature level, scaling laws at the algebraic equation level, and governing equations at the differential equation level. This fusion of knowledge and AI could unlock an exciting new era of scientific discovery and understanding.</p>
<p>The details of my research are shown below:</p>
<h2 id="1-Data-driven-discovery-of-universal-laws"><a href="#1-Data-driven-discovery-of-universal-laws" class="headerlink" title="1. Data-driven discovery of universal laws"></a><strong>1. Data-driven discovery of universal laws</strong></h2><p><strong>1.1 Dimensionless Learning (Dimensional Analysis + Machine Learning) for scientific discovery</strong></p>
<p>Dimensionless learning combines fundamental physics principles with state-of-the-art machine learning techniques to solve scientific and engineering problems. By embedding the principle of dimensional invariance into a two-level machine learning scheme, it can automatically discover dominant dimensionless numbers and governing laws (scaling laws and differential equations) from noisy and scarce measurements.</p>
<ul>
<li><strong>Xie, X.</strong>, Samaei, A., Guo, J., Liu, W. K., &amp; Gan, Z., (2022). Data-driven discovery of dimensionless numbers and governing laws from scarce measurements. <strong><em>Nature Communications</em></strong>, 13, 7562. <a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41467-022-35084-w">https://doi.org/10.1038/s41467-022-35084-w</a>. <a target="_blank" rel="noopener" href="https://github.com/xiaoyuxie-vico/PyDimension"><span style="color:red"><strong>Code</strong></span></a>. <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=b3y4ksYzcig"><span style="color:red"><strong>CMU talk recording</strong></span></a>.</li>
</ul>
<p align="center">
  <img height="500px" src="/images/DimensionlessLearning.png">
</p>

<p><strong>1.2 Dimensionally invariant Neural Network (DimensionNet) for scientific discovery</strong></p>
<p>The DimensionNet reduces the dimensionality of the original input parameters by automatically discovering a smaller set of governing dimensionless numbers and transforming the high-dimensional inputs to the dimensionless set. </p>
<ul>
<li>Saha, S., Gan, Z., Cheng, L., Gao, J., Kafka, O. L., <strong>Xie, X.</strong>, Li, H., Tajdari, M., Kim, H. A., &amp; Liu, W. K. (2021). Hierarchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational science and engineering. <strong><em>Computer Methods in Applied Mechanics and Engineering</em></strong>, 373, 113452. <br><a target="_blank" rel="noopener" href="https://doi.org/10.1016/j.cma.2020.113452"><strong>Paper</strong></a></li>
</ul>
<p align="center">
  <img height="300px" src="/images/DimensionNet.png">
</p>

<h2 id="2-Data-driven-reduced-order-modeling"><a href="#2-Data-driven-reduced-order-modeling" class="headerlink" title="2. Data-driven reduced-order modeling"></a><strong>2. Data-driven reduced-order modeling</strong></h2><p><strong>Smooth and sparse latent dynamics in operator learning with jerk regularization</strong></p>
<p>Spatiotemporal modeling is critical for understanding complex systems across various scientific and engineering disciplines, but governing equations are often not fully known or computationally intractable due to inherent system complexity. Data-driven reduced-order models (ROMs) offer a promising approach for fast and accurate spatiotemporal forecasting by computing solutions in a compressed latent space. However, these models often neglect temporal correlations between consecutive snapshots when constructing the latent space, leading to suboptimal compression, jagged latent trajectories, and limited extrapolation ability over time. To address these issues, this paper introduces a continuous operator learning framework that incorporates jerk regularization into the learning of the compressed latent space. This jerk regularization promotes smoothness and sparsity of latent space dynamics, which not only yields enhanced accuracy and convergence speed but also helps identify intrinsic latent space coordinates. Consisting of an implicit neural representation (INR)-based autoencoder and a neural ODE latent dynamics model, the framework allows for inference at any desired spatial or temporal resolution. The effectiveness of this framework is demonstrated through a two-dimensional unsteady flow problem governed by the Navier-Stokes equations, highlighting its potential to expedite high-fidelity simulations in various scientific and engineering applications.</p>
<p align="center">
  <img height="800px" src="/images/OperatorLearning.png">
</p>

<ul>
<li><strong>Xie, X.</strong>, Mowlavi, S., Benosman, M., (2024). Smooth and sparse latent dynamics in operator learning with jerk regularization. arXiv preprint arXiv:2402.15636.<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.15636"><strong>Paper</strong></a></li>
</ul>
<h2 id="3-Machine-Learning-based-Digital-Twin"><a href="#3-Machine-Learning-based-Digital-Twin" class="headerlink" title="3. Machine Learning-based Digital Twin"></a><strong>3. Machine Learning-based Digital Twin</strong></h2><p><strong>AI-empowered scientific discovery and digital twin in additive manufacturing</strong></p>
<p>Metal additive manufacturing provides remarkable flexibility in geometry and component design, but localized heating/cooling heterogeneity leads to spatial variations of as-built mechanical properties, significantly complicating the materials design process. To this end, we develop a mechanistic data-driven framework integrating wavelet transforms and convolutional neural networks to predict location-dependent mechanical properties over fabricated parts based on process-induced temperature sequences, i.e., thermal histories. The framework enables multiresolution analysis and importance analysis to reveal dominant mechanistic features underlying the additive manufacturing process, such as critical temperature ranges and fundamental thermal frequencies. We systematically compare the developed approach with other machine learning methods. The results demonstrate that the developed approach achieves reasonably good predictive capability using a small amount of noisy experimental data. It provides a concrete foundation for a revolutionary methodology that predicts spatial and temporal evolution of mechanical properties leveraging domain-specific knowledge and cutting-edge machine and deep learning technologies.</p>
<p align="center">
  <img height="600px" src="/images/npj.png">
</p>

<ul>
<li><strong>Xie, X.</strong>, Bennett, J., Saha, S., Lu, Y., Cao, J., Liu, W. K., &amp; Gan, Z. (2021). Mechanistic data-driven prediction of as-built mechanical properties in metal additive manufacturing. <strong><em>Npj Computational Materials</em></strong>, 7(1), 1–12.<br><a target="_blank" rel="noopener" href="https://doi.org/10.1038/s41524-021-00555-z"><strong>Paper</strong></a></li>
</ul>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/#Home"> Home</a></li><li class="nav_item"><a class="nav-page" href="/Research"> Research</a></li><li class="nav_item"><a class="nav-page" href="/Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/Awards"> Awards</a></li><li class="nav_item"><a class="nav-page" href="/Teaching"> Teaching</a></li><li class="nav_item"><a class="nav-page" href="/Media"> Media</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2024 by Xiaoyu Xie</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>